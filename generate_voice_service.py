from flask import Flask, request, jsonify
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
import torchaudio
from ChatTTS import ChatTTS
import soundfile

app = Flask(__name__)

# =============== 1. 初始化 ===============
chat = ChatTTS.Chat()
chat.load(compile=False) # 或 compile=True
print("ChatTTS model loaded.")

# =============== 2. 生成或加载音色字符串 ===============
# 设置为 True 来加载之前保存的音色
LOAD_SAVED_SPEAKER = True

if LOAD_SAVED_SPEAKER:
    # --- 加载已保存的音色字符串 ---
    SPEAKER_STR_FILE = "voices/saved_speaker_string.txt"
    try:
        with open(SPEAKER_STR_FILE, 'r', encoding='utf-8') as f:
            rand_spk_str = f.read().strip()
        print(f"✅ Loaded speaker string from '{SPEAKER_STR_FILE}'. Length: {len(rand_spk_str)}")
    except FileNotFoundError:
        print(f"❌ File '{SPEAKER_STR_FILE}' not found. Generating a new one.")
        rand_spk_str = chat.sample_random_speaker()
    except Exception as e:
        print(f"❌ Error loading speaker string: {e}. Generating a new one.")
        rand_spk_str = chat.sample_random_speaker()
else:
    # --- 生成新的音色字符串 ---
    rand_spk_str = chat.sample_random_speaker()
    print(f"🆕 Generated new speaker string. Length: {len(rand_spk_str)}")
    
    # --- 保存新生成的音色字符串 ---
    SPEAKER_STR_FILE = "saved_speaker_string.txt"
    try:
        with open(SPEAKER_STR_FILE, 'w', encoding='utf-8') as f:
            f.write(rand_spk_str)
        print(f"💾 Saved new speaker string to '{SPEAKER_STR_FILE}'.")
    except Exception as e:
        print(f"❌ Failed to save speaker string: {e}")

# 推理函数
def generate_voice(prompt):
        # =============== 3. 设置推理参数 ===============
    # 直接使用字符串形式的 rand_spk_str
    params_infer_code = ChatTTS.Chat.InferCodeParams(
        spk_emb=rand_spk_str,  # 注意：这里传入的是 STRING!
    )

    # =============== 4. 生成语音 ===============
    texts = [prompt]
    print(f"📝 Generating speech for: '{texts[0]}'")

    try:
        wavs = chat.infer(texts, params_infer_code=params_infer_code)
        if wavs and len(wavs) > 0 and wavs[0] is not None:
            # 假设 wavs[0] 是 numpy 数组
            wav_data = wavs[0]
            # 确保是正确的形状 (通常是 (samples,) 或 (1, samples))
            if wav_data.ndim == 1:
                audio_tensor = torch.from_numpy(wav_data).unsqueeze(0) # (samples,) -> (1, samples)
            else:
                audio_tensor = torch.from_numpy(wav_data)
            
            # 保存音频
            OUTPUT_WAV = "dist/Resources/Haru/sounds/audio.wav"
            soundfile.write(OUTPUT_WAV, audio_tensor[0].numpy(), 24000)
            print(f"🎉 Speech generated and saved to '{OUTPUT_WAV}'.")
        else:
            print("❌ No audio data generated by 'infer'.")
    except Exception as e:
        print(f"❌ Error during inference: {e}")

    print("✅ Script completed.")

# 定义 API 接口
@app.route("/generate", methods=["POST"])
def generate():
    try:
        data = request.json
        prompt = data.get("prompt", "你好")
        generate_voice(prompt)
        
        return jsonify({"response": prompt})
        
    except Exception as e:
        print(f"Error in chat endpoint: {e}")
        return jsonify({"response": "抱歉，出现了一些问题，请稍后再试。"}), 500

# 启动服务
if __name__ == "__main__":
    print("Starting generate voice service...")
    app.run(host="0.0.0.0", port=5001, debug=False)