from flask import Flask, request, jsonify
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
import torchaudio
from ChatTTS import ChatTTS
import soundfile

app = Flask(__name__)

# =============== 1. åˆå§‹åŒ– ===============
chat = ChatTTS.Chat()
chat.load(compile=False) # æˆ– compile=True
print("ChatTTS model loaded.")

# =============== 2. ç”Ÿæˆæˆ–åŠ è½½éŸ³è‰²å­—ç¬¦ä¸² ===============
# è®¾ç½®ä¸º True æ¥åŠ è½½ä¹‹å‰ä¿å­˜çš„éŸ³è‰²
LOAD_SAVED_SPEAKER = True

if LOAD_SAVED_SPEAKER:
    # --- åŠ è½½å·²ä¿å­˜çš„éŸ³è‰²å­—ç¬¦ä¸² ---
    SPEAKER_STR_FILE = "voices/saved_speaker_string.txt"
    try:
        with open(SPEAKER_STR_FILE, 'r', encoding='utf-8') as f:
            rand_spk_str = f.read().strip()
        print(f"âœ… Loaded speaker string from '{SPEAKER_STR_FILE}'. Length: {len(rand_spk_str)}")
    except FileNotFoundError:
        print(f"âŒ File '{SPEAKER_STR_FILE}' not found. Generating a new one.")
        rand_spk_str = chat.sample_random_speaker()
    except Exception as e:
        print(f"âŒ Error loading speaker string: {e}. Generating a new one.")
        rand_spk_str = chat.sample_random_speaker()
else:
    # --- ç”Ÿæˆæ–°çš„éŸ³è‰²å­—ç¬¦ä¸² ---
    rand_spk_str = chat.sample_random_speaker()
    print(f"ğŸ†• Generated new speaker string. Length: {len(rand_spk_str)}")
    
    # --- ä¿å­˜æ–°ç”Ÿæˆçš„éŸ³è‰²å­—ç¬¦ä¸² ---
    SPEAKER_STR_FILE = "saved_speaker_string.txt"
    try:
        with open(SPEAKER_STR_FILE, 'w', encoding='utf-8') as f:
            f.write(rand_spk_str)
        print(f"ğŸ’¾ Saved new speaker string to '{SPEAKER_STR_FILE}'.")
    except Exception as e:
        print(f"âŒ Failed to save speaker string: {e}")

# æ¨ç†å‡½æ•°
def generate_voice(prompt):
        # =============== 3. è®¾ç½®æ¨ç†å‚æ•° ===============
    # ç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²å½¢å¼çš„ rand_spk_str
    params_infer_code = ChatTTS.Chat.InferCodeParams(
        spk_emb=rand_spk_str,  # æ³¨æ„ï¼šè¿™é‡Œä¼ å…¥çš„æ˜¯ STRING!
    )

    # =============== 4. ç”Ÿæˆè¯­éŸ³ ===============
    texts = [prompt]
    print(f"ğŸ“ Generating speech for: '{texts[0]}'")

    try:
        wavs = chat.infer(texts, params_infer_code=params_infer_code)
        if wavs and len(wavs) > 0 and wavs[0] is not None:
            # å‡è®¾ wavs[0] æ˜¯ numpy æ•°ç»„
            wav_data = wavs[0]
            # ç¡®ä¿æ˜¯æ­£ç¡®çš„å½¢çŠ¶ (é€šå¸¸æ˜¯ (samples,) æˆ– (1, samples))
            if wav_data.ndim == 1:
                audio_tensor = torch.from_numpy(wav_data).unsqueeze(0) # (samples,) -> (1, samples)
            else:
                audio_tensor = torch.from_numpy(wav_data)
            
            # ä¿å­˜éŸ³é¢‘
            OUTPUT_WAV = "dist/Resources/Haru/sounds/audio.wav"
            soundfile.write(OUTPUT_WAV, audio_tensor[0].numpy(), 24000)
            print(f"ğŸ‰ Speech generated and saved to '{OUTPUT_WAV}'.")
        else:
            print("âŒ No audio data generated by 'infer'.")
    except Exception as e:
        print(f"âŒ Error during inference: {e}")

    print("âœ… Script completed.")

# å®šä¹‰ API æ¥å£
@app.route("/generate", methods=["POST"])
def generate():
    try:
        data = request.json
        prompt = data.get("prompt", "ä½ å¥½")
        generate_voice(prompt)
        
        return jsonify({"response": prompt})
        
    except Exception as e:
        print(f"Error in chat endpoint: {e}")
        return jsonify({"response": "æŠ±æ­‰ï¼Œå‡ºç°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"}), 500

# å¯åŠ¨æœåŠ¡
if __name__ == "__main__":
    print("Starting generate voice service...")
    app.run(host="0.0.0.0", port=5001, debug=False)